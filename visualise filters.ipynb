{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters visualisation with matplotlib in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import math\n",
    "import keras.callbacks\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The below code is for Jetson. Without it has SSL Certificate error.\n",
    "\n",
    "#import ssl\n",
    "# This restores the same behavior as before.\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd6343d4d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAYL329OsCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd63055ce50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change shape\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# Convert to float32 and normalise to range [0,1]\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), data_format=\"channels_first\", activation='tanh', input_shape=(1,28,28)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(K.tanh))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 26, 26)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 24, 32)        7520      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5760)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               737408    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 746,538\n",
      "Trainable params: 746,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 249s - loss: 0.2295 - acc: 0.9304   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 246s - loss: 0.1022 - acc: 0.9694   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 247s - loss: 0.0808 - acc: 0.9751   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 251s - loss: 0.0695 - acc: 0.9786   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 253s - loss: 0.0666 - acc: 0.9797   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 252s - loss: 0.0600 - acc: 0.9821   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 247s - loss: 0.0546 - acc: 0.9833   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 246s - loss: 0.0506 - acc: 0.9848   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 245s - loss: 0.0522 - acc: 0.9847   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 246s - loss: 0.0477 - acc: 0.9854   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd635c9dfd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s[0.033523569321696776, 0.98999999999999999]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export model\n",
    "#json_string = model.to_json()\n",
    "#open('my_model_architecture.json', 'w').write(json_string)\n",
    "\n",
    "yaml_string = model.to_yaml()\n",
    "open('my_model_architecture.yml', 'w').write(yaml_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-283638baff05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "#model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise filters\n",
    "\n",
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flatten_3': <keras.layers.core.Flatten object at 0x7fd63602b210>, 'activation_3': <keras.layers.core.Activation object at 0x7fd636066410>, 'dense_6': <keras.layers.core.Dense object at 0x7fd635ff37d0>, 'dense_5': <keras.layers.core.Dense object at 0x7fd63602b750>, 'max_pooling2d_3': <keras.layers.pooling.MaxPooling2D object at 0x7fd63601a690>, 'dropout_5': <keras.layers.core.Dropout object at 0x7fd636278d50>, 'dropout_6': <keras.layers.core.Dropout object at 0x7fd63602b190>, 'conv2d_5': <keras.layers.convolutional.Conv2D object at 0x7fd636066910>, 'conv2d_6': <keras.layers.convolutional.Conv2D object at 0x7fd63607a3d0>}\n"
     ]
    }
   ],
   "source": [
    "print layer_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ref.: Keras model https://keras.io/models/model/*\n",
    "\n",
    "model.inputs – list of input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_outputs(layer_name, input_img_data):\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    layer_f = K.function(model.inputs, [layer_output])\n",
    "    outputs = np.asarray(layer_f([[input_img_data]]), dtype=np.float32)[0][0]\n",
    "    return outputs\n",
    "\n",
    "def get_layer_filters(layer_name):\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    filters = layer_dict[layer_name].output[0]\n",
    "    print \"Filters:\", filters\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters: Tensor(\"strided_slice_6:0\", shape=(32, 26, 26), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(32, 26, 26)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-8028b3056cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilter_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_row\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0minvoked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \"\"\"\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Tensor' object is not iterable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not iterable."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAYL329OsCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6153303d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd615317850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "#print X_train[12,0].shape\n",
    "plt.imshow(X_train[12,0])\n",
    "\n",
    "filters = get_layer_filters(\"conv2d_7\")\n",
    "print type(filters)\n",
    "print filters.shape\n",
    "in_row = 8.\n",
    "fshape = float(x)\n",
    "rows = math.ceil(fshape/in_row)\n",
    "\n",
    "fig = plt.figure()\n",
    "i = 0\n",
    "for filter_ in filters[0]:\n",
    "    p=fig.add_subplot(rows,in_row,i+1)\n",
    "    p.axis('off')\n",
    "    plt.imshow(filter_, cmap=\"gray\")\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 9\n",
    "fig = plt.figure()\n",
    "plt.imshow(X_train[img_index,0])\n",
    "\n",
    "filters = get_layer_filters(\"conv2d_1\", X_train[img_index])\n",
    "fig = plt.figure()\n",
    "in_row = 8.\n",
    "rows = math.ceil(filters.shape[0]/in_row)\n",
    "i = 0\n",
    "for filter_ in filters:\n",
    "    p=fig.add_subplot(rows,in_row,i+1)\n",
    "    p.axis('off')\n",
    "    plt.imshow(filter_)\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 9\n",
    "fig = plt.figure()\n",
    "plt.imshow(X_train[img_index,0])\n",
    "\n",
    "filters = get_layer_filters(\"conv2d_2\", X_train[img_index])\n",
    "fig = plt.figure()\n",
    "in_row = 6.\n",
    "rows = math.ceil(filters.shape[0]/in_row)\n",
    "i = 0\n",
    "for filter_ in filters:    \n",
    "    p=fig.add_subplot(rows,in_row,i+1)\n",
    "    p.axis('off')\n",
    "    plt.imshow(filter_)\n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 9\n",
    "fig = plt.figure()\n",
    "plt.imshow(X_train[img_index,0])\n",
    "\n",
    "filters = get_layer_filters(\"max_pooling2d_1\", X_train[img_index])\n",
    "fig = plt.figure()\n",
    "in_row = 6.\n",
    "rows = math.ceil(filters.shape[0]/in_row)\n",
    "i = 0\n",
    "for filter_ in filters:    \n",
    "    p=fig.add_subplot(rows,in_row,i+1)\n",
    "    p.axis('off')\n",
    "    plt.imshow(filter_)\n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
